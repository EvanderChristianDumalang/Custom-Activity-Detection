{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "with open('model_name.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# For static images:\n",
    "data = []\n",
    "img_dir = \"directory path for images\"  # Enter Directory of all images\n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "BG_COLOR = (192, 192, 192)  # gray\n",
    "with mp_pose.Pose(\n",
    "        static_image_mode=True,\n",
    "        model_complexity=0,\n",
    "        enable_segmentation=True,\n",
    "        min_detection_confidence=0.1) as pose:\n",
    "\n",
    "    for idx, file in enumerate(files):\n",
    "        try:\n",
    "            image = cv2.imread(file)\n",
    "            image_height, image_width, _ = image.shape\n",
    "            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            print(idx, file)\n",
    "\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                annotated_image = image.copy()\n",
    "                condition = np.stack(\n",
    "                    (results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "                bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "                bg_image[:] = BG_COLOR\n",
    "                annotated_image = np.where(\n",
    "                    condition, annotated_image, bg_image)\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    annotated_image,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "                # Extract Pose landmarks\n",
    "                data = results.pose_landmarks.landmark\n",
    "                pose_row = list(np.array(\n",
    "                    [[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in data]).flatten())\n",
    "                del pose_row[0:40]\n",
    "                row = (pose_row)\n",
    "\n",
    "                # Make Detections\n",
    "                X = pd.DataFrame([row])\n",
    "                body_language_class = model.predict(X)[0]\n",
    "                body_language_prob = model.predict_proba(X)[0]\n",
    "\n",
    "                # Get status box\n",
    "                cv2.rectangle(annotated_image, (0, 0),\n",
    "                              (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "                # Display Class\n",
    "                cv2.putText(annotated_image, 'CLASS', (95, 12),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(annotated_image, body_language_class.split(' ')[\n",
    "                            0], (90, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Display Probability\n",
    "                cv2.putText(annotated_image, 'PROB', (15, 12),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(annotated_image, str(round(body_language_prob[np.argmax(\n",
    "                    body_language_prob)], 2)), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.imwrite(r'directory path for result' +\n",
    "                            str(idx) + '.png', annotated_image)\n",
    "        except:\n",
    "            pass\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4f35bca6a71977831938391b01dd58e3be6d850637f3133a6b1f36e4548f4f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
